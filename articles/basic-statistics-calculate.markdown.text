这篇文章总结了概率统计中期望、方差、协方差和相关系数的定义、性质和基本运算规则。

# 期望
## 定义
设\\(P(x)\\)是一个离散概率分布函数，自变量的取值范围为\\(\\{x\_1, x\_2, \\cdots, \\x\_n\\}\\)。其期望被定义为：

\\[E(x)=sum\_{k=1}^n{x\_kP(x\_k)}\\]

设\\(p(x)\\)是一个连续概率密度函数。其期望为：

\\[E(x)=\\int\_{-\\infty}^{+\\infty}{xp(x)dx}\\]

## 性质
1、线性运算规则

期望服从线性性质（可以很容易从期望的定义公式中导出）。因此线性运算的期望等于期望的线性运算：

\\[E(ax+by+c)=aE(x)+bE(y)+c\\]

这个性质可以推广到任意一般情况：

\\[E(\\sum\_{k=1}^{n}{a\_ix\_i}+c)=\\sum\_{k=1}^{n}{a\_iE(x\_i)}+c\\]

2、函数的期望

设\\(f(x)\\)为x的函数，则\\(f(x)\\)的期望为：

离散：

\\[E(f(x))=sum\_{k=1}^n{f(x\_k)P(x\_k)}\\]

连续：

\\[E(f(x))=\\int\_{-\\infty}^{+\\infty}{f(x)p(x)dx}\\]

一定要注意，_函数的期望不等于期望的函数_，即\\(E(f(x)) \\ne f(E(x))\\)！。

3、乘积的期望

一般来说，_乘积的期望不等于期望的乘积_，除非变量相互独立。因此，如果x和y相互独立，则\\(E(xy)=E(x)E(x)\\)。

期望的运算构成了统计量的运算基础，因为_方差、协方差等统计量本质上是一种特殊的期望_。
